{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**IGNORE**\n",
    "\n",
    "First we need to import some stuff. Feel free to ignore this cell.\n",
    "\n",
    "If you're interested, each import has an associated comment that explains why\n",
    "the import is useful/necessary.\n",
    "\"\"\"\n",
    "\n",
    "# Needed for various filesystem tasks (os.path.exists etc.)\n",
    "import os\n",
    "# Used for checking how many cores are available for processing.\n",
    "import multiprocessing\n",
    "# Used for constructing paths.\n",
    "from pathlib import Path\n",
    "\n",
    "# Essential for all mathematical operations we'll be carrying out.\n",
    "import numpy as np\n",
    "\n",
    "# diffraction_utils is a library developed at Diamond by Richard Brearton\n",
    "# (richard.brearton@diamond.ac.uk) to ease the task of parsing data files and\n",
    "# carrying out some common calculations. Here, we'll be using it to define\n",
    "# frames of reference, and parse nexus files.\n",
    "# We also use diffraction_utils' Region object to specify regions of interest/\n",
    "# background regions.\n",
    "from diffraction_utils import Frame, Region\n",
    "\n",
    "# The following imports are required for the core of the calculation code, also\n",
    "# written by Richard Brearton (richard.brearton@diamond.ac.uk).\n",
    "# This is the central Experiment object, which stores all the logic related to\n",
    "# mapping the experiment.\n",
    "from fast_rsm.experiment import Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**ESSENTIAL**\n",
    "\n",
    "This cell requires action! Make sure you set all of the variables defined here.\n",
    "\"\"\"\n",
    "\n",
    "# What was your scattering geometry/how was your sample mounted? Options are\n",
    "# 'horizontal', 'vertical' and 'DCD'.\n",
    "setup = 'vertical'\n",
    "\n",
    "# Only set these is you want your code to run locally, and not on the cluster.\n",
    "# Be warned that this will be much slower. Only do this if your data has been\n",
    "# deleted from data storage and you've had to restore it from tape, or brought\n",
    "# your own hard drive. So: UNLESS YOU'RE TOLD, LEAVE AS None.\n",
    "local_data_path = None\n",
    "local_output_path = None\n",
    "\n",
    "# If you're processing on the cluster, you need to populate the next few fields.\n",
    "# The experiment number, used to work out where your data is stored.\n",
    "experiment_number = 'si31695-1'\n",
    "\n",
    "# The sub-directory containing your experimental data. Leave as None if unused.\n",
    "# Otherwise, if the data was stored in a subdirectory called \"day_1\", e.g.\n",
    "#   /dls/i07/data/2022/si32333-1/day_1/\n",
    "# then you should use:\n",
    "#   data_sub_directory = \"day_1\"\n",
    "data_sub_directory = \"Ag100clean/\"\n",
    "\n",
    "# The year the experiment took place.\n",
    "year = 2022\n",
    "\n",
    "# The scan numbers of the scans that we want to use to produce this reciprocal\n",
    "# space map. For example, the default value of scan_numbers shows how to specify\n",
    "# every scan between number 421772 and 421778 inclusive, but skipping scan\n",
    "# number 421776.\n",
    "scan_numbers = [445500, 445501, 445502]\n",
    "\n",
    "# Uncomment the following to set scan_numbers equal to every scan number between\n",
    "# scan_start and scan_stop (inclusive of scan_stop):\n",
    "# scan_start = 439168\n",
    "# scan_stop = 439176\n",
    "# scan_numbers = list(range(scan_start, scan_stop + 1))\n",
    "\n",
    "# The beam centre, as can be read out from GDA, in pixel_x, pixel_y. If your\n",
    "# map looks wacky, you probably cocked this up.\n",
    "beam_centre = (242, 95)\n",
    "\n",
    "# The distance between the sample and the detector (or, if using the DCD, the\n",
    "# distance between the receiving slit and the detector). Units of meters.\n",
    "detector_distance = 930e-3\n",
    "\n",
    "# The frame/coordinate system you want the map to be carried out in.\n",
    "# Options for frame_name argument are:\n",
    "#     Frame.hkl     (map into hkl space - requires UB matrix in nexus file)\n",
    "#     Frame.sample_holder   (standard map into 1/Ã…)\n",
    "#     Frame.lab     (map into frame attached to lab.)\n",
    "#     Frame.qpar_qperp (as in Frame.lab, but with no component along beam)\n",
    "#\n",
    "# Please note that the q_parallel q_perpendicular frame is a bad choice. Q is a\n",
    "# three dimensional vector. By choosing this frame, you are consenting to\n",
    "# throwing one of these dimensions in the bin. Instead consider Frame.lab.\n",
    "#\n",
    "# Options for coordinates argument are:\n",
    "#     Frame.cartesian   (normal cartesian coords: hkl, Qx Qy Qz, etc.)\n",
    "#     Frame.polar       (cylindrical polar with cylinder axis along l/Qz)\n",
    "#\n",
    "# Frame.polar will give an output like a more general version of PyFAI.\n",
    "# Frame.cartesian is for hkl maps and Qx/Qy/Qz. Any combination of frame_name\n",
    "# and coordinates will work, so try them out; get a feel for them.\n",
    "frame_name = Frame.hkl\n",
    "coordinates = Frame.cartesian\n",
    "\n",
    "# How large would you like your output file to be, in MB? 100MB normally gives\n",
    "# very good resolution without sacrificing performance. If you want something\n",
    "# higher resolution, feel free, but be aware that the performance of the map and\n",
    "# the analysis will start to suffer above around 1GB.\n",
    "# Max file size is 2GB (2000MB).\n",
    "output_file_size = 100\n",
    "\n",
    "# What do you want to do? Processing time is linear in the number of these you\n",
    "# set to True. I could definitely make that cleverer in the future, though.\n",
    "save_volume = True # This is for loading into paraview.\n",
    "intensity_vs_Q = False # I vs |Q|\n",
    "intensity_vs_l = False # I vs l\n",
    "intensity_vs_tth = False # I vs total scattered two theta.\n",
    "\n",
    "# The DPS central pixel locations are not typically recorded in the nexus file.\n",
    "dpsx_central_pixel = 0\n",
    "dpsy_central_pixel = 0\n",
    "dpsz_central_pixel = 0\n",
    "\n",
    "# Note: THESE CAN BE HAPPILY AUTO CALCULATED.\n",
    "# These take the form:\n",
    "# volume_start = [h_start, k_start, l_start]\n",
    "# volume_stop = [h_stop, k_stop, l_stop]\n",
    "# volume_step = [h_step, k_step, l_step]\n",
    "# Leave as None if you don't want to specify them. You can specify whichever\n",
    "# you like (e.g. you can specify step and allow start/stop to be auto\n",
    "# calculated)\n",
    "volume_start = None\n",
    "volume_stop = None\n",
    "volume_step = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**MASKING**\n",
    "\n",
    "This cell contains details on how to mask pixels. You can either mask a series\n",
    "of individual pixels, mask rectangular regions of pixels, or dynamically mask\n",
    "pixels based on their intensity (not recommended).\n",
    "\"\"\"\n",
    "\n",
    "# If you have a small number of hot pixels to mask, specify them one at a time\n",
    "# in a list. In other words, it should look like:\n",
    "# specific_pixels = [(pixel_x1, pixel_y1), (pixel_x2, pixel_y2)]\n",
    "# Or, an exact example, where we want to mask pixel (233, 83) and pixel \n",
    "# (234, 83), where pixel coordinates are (x, y):\n",
    "# \n",
    "# specific_pixels = [\n",
    "#     (233, 83),\n",
    "#     (234, 83)\n",
    "# ]\n",
    "# \n",
    "# Leave specific pixels as None if you dont want to mask any specific pixels.\n",
    "specific_pixels = None\n",
    "\n",
    "# If you want to specify an entire region of pixels to mask, do so here.\n",
    "# This is done using a \"Region\" object. To make a Region, give it start_x, \n",
    "# stop_x, start_y, start_y, as follows:\n",
    "# \n",
    "my_mask_region = Region(3, 6, 84, 120)\n",
    "# \n",
    "# Where my_mask_region runs in x from pixel 3 to 6 inclusive, and runs in y from\n",
    "# pixel 84 to 120 inclusive. You can make as many mask regions as you like, just\n",
    "# make sure that you put them in the mask_regions list, as follows:\n",
    "# mask_regions = [my_mask_region, Region(1, 2, 3, 4)]\n",
    "# \n",
    "# If you don't want to use any mask regions, just leave mask_regions equal to\n",
    "# None.\n",
    "mask_regions = None\n",
    "\n",
    "# Ignore pixels with an intensity below this value. If you don't want to ignore\n",
    "# any pixels, then set min_intensity = None. This is useful for dynamically\n",
    "# creating masks (which, in retrospect... might not actually be useful).\n",
    "min_intensity = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**IGNORE**\n",
    "This cell prepares the calculation. You probably shouldn't change anything here\n",
    "unless you know what you're doing.\n",
    "\"\"\"\n",
    "\n",
    "# Which synchrotron axis should become the out-of-plane (001) direction.\n",
    "# Defaults to 'y'; can be 'x', 'y' or 'z'.\n",
    "if setup == 'vertical':\n",
    "    oop = 'x'\n",
    "elif setup == 'horizontal':\n",
    "    oop = 'y'\n",
    "elif setup == 'DCD':\n",
    "    oop = 'y'\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Setup not recognised. Must be 'vertical', 'horizontal' or 'DCD.\")\n",
    "\n",
    "if output_file_size > 2000:\n",
    "    raise ValueError(\"output_file_size must not exceed 2000. \"\n",
    "                     f\"Value received was {output_file_size}.\")\n",
    "\n",
    "# Max number of cores available for processing.\n",
    "num_threads = multiprocessing.cpu_count()\n",
    "\n",
    "# Work out where the data is.\n",
    "if local_data_path is None:\n",
    "    data_dir = Path(f\"/dls/i07/data/{year}/{experiment_number}/\")\n",
    "else:\n",
    "    data_dir = Path(local_data_path)\n",
    "# data_dir = Path(f\"/Users/richard/Data/i07/{experiment_number}/\")\n",
    "\n",
    "# Store this for later.\n",
    "if local_output_path is None:\n",
    "    processing_dir = data_dir / \"processing\"\n",
    "else:\n",
    "    processing_dir = Path(local_output_path)\n",
    "if data_sub_directory is not None:\n",
    "    data_dir /= Path(data_sub_directory)\n",
    "\n",
    "# Here we calculate a sensible file name that hasn't been taken.\n",
    "i = 0\n",
    "save_file_name = f\"mapped_scan_{scan_numbers[0]}_{i}\"\n",
    "save_path = processing_dir / save_file_name\n",
    "# Make sure that this name hasn't been used in the past.\n",
    "while (os.path.exists(str(save_path) + \".npy\") or\n",
    "       os.path.exists(str(save_path) + \".vtk\") or\n",
    "       os.path.exists(str(save_path) + \"_l.txt\") or\n",
    "       os.path.exists(str(save_path) + \"_tth.txt\") or\n",
    "       os.path.exists(str(save_path) + \"_Q.txt\") or\n",
    "       os.path.exists(save_path)):\n",
    "    i += 1\n",
    "    save_file_name = f\"mapped_scan_{scan_numbers[0]}_{i}\"\n",
    "    save_path = processing_dir / save_file_name\n",
    "\n",
    "    if i > 1e7:\n",
    "        raise ValueError(\n",
    "            \"Either you tried to save this file 10000000 times, or something \"\n",
    "            \"went wrong. I'm going with the latter, but exiting out anyway.\")\n",
    "\n",
    "\n",
    "# Work out the paths to each of the nexus files. Store as pathlib.Path objects.\n",
    "nxs_paths = [data_dir / f\"i07-{x}.nxs\" for x in scan_numbers]\n",
    "\n",
    "# Construct the Frame object from the user's preferred frame/coords.\n",
    "map_frame = Frame(frame_name=frame_name, coordinates=coordinates)\n",
    "\n",
    "# Prepare the pixel mask. First, deal with any specific pixels that we have.\n",
    "# Note that these are defined (x, y) and we need (y, x) which are the\n",
    "# (slow, fast) axes. So: first we need to deal with that!\n",
    "if specific_pixels is not None:\n",
    "    specific_pixels = specific_pixels[1], specific_pixels[0]\n",
    "\n",
    "# Now deal with any regions that may have been defined.\n",
    "# First make sure we have a list of regions.\n",
    "if isinstance(mask_regions, Region):\n",
    "    mask_regions = [mask_regions]\n",
    "\n",
    "# Now swap (x, y) for each of the regions.\n",
    "if mask_regions is not None:\n",
    "    for region in mask_regions:\n",
    "        region.x_start, region.y_start = region.y_start, region.x_start\n",
    "        region.x_end, region.y_end = region.y_end, region.x_end\n",
    "\n",
    "# Finally, instantiate the Experiment object.\n",
    "experiment = Experiment.from_i07_nxs(\n",
    "    nxs_paths, beam_centre, detector_distance, setup)\n",
    "\n",
    "experiment.mask_pixels(specific_pixels)\n",
    "experiment.mask_regions(mask_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**POTENTIALLY REQUIRED**\n",
    "\n",
    "This cell is for changing metadata that is stored in, or inferred from, the\n",
    "nexus file. This is generally for more nonstandard stuff.\n",
    "\"\"\"\n",
    "\n",
    "for i, scan in enumerate(experiment.scans):\n",
    "    # Deal with the dps offsets.\n",
    "    scan.metadata.data_file.dpsx -= dpsx_central_pixel\n",
    "    scan.metadata.data_file.dpsy -= dpsy_central_pixel\n",
    "    scan.metadata.data_file.dpsz -= dpsz_central_pixel\n",
    "\n",
    "    # These example nexus data files are broken. The data needs to be backed up\n",
    "    # from .dat files, which contains the motor positions. Comment this out in\n",
    "    # the likely event that you don't need to do this. If you do need to back\n",
    "    # up your motor positions from a dat file, leave this code in.\n",
    "    dat_path = data_dir / f\"{scan_numbers[i]}.dat\"\n",
    "    scan.metadata.data_file.populate_data_from_dat(dat_path)\n",
    "\n",
    "    # This is where you might want to overwrite some data that was recorded\n",
    "    # badly in the nexus file. See (commented out) examples below.\n",
    "    # scan.metadata.data_file.probe_energy = 12500\n",
    "    # scan.metadata.data_file.transmission = 0.4\n",
    "    # scan.metadata.data_file.using_dps = True\n",
    "    # scan.metadata.data_file.ub_matrix = np.array([\n",
    "    #     [1, 0, 0],\n",
    "    #     [0, 1, 0],\n",
    "    #     [0, 0, 1]\n",
    "    # ])\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**IGNORE**\n",
    "\n",
    "This cell contains all of the logic for running the calculation. You shouldn't\n",
    "run this on your local computer, it'll either raise an exception or take\n",
    "forever.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Calculate and save a binned reciprocal space map, if requested.\n",
    "    if save_volume:\n",
    "        experiment.binned_reciprocal_space_map(\n",
    "        num_threads, map_frame, output_file_size=output_file_size, oop=oop,\n",
    "        output_file_name=save_path, \n",
    "        volume_start=volume_start, volume_stop=volume_stop,\n",
    "        volume_step=volume_step)\n",
    "\n",
    "    # Calculate I(l) if requested.\n",
    "    if intensity_vs_l:\n",
    "        intensity, l = experiment.intensity_vs_l(\n",
    "        num_threads, oop=oop, output_file_name=save_path)\n",
    "\n",
    "    # Calculate I(Q) if requested.\n",
    "    if intensity_vs_Q:\n",
    "        intensity, q = experiment.intensity_vs_q(\n",
    "        num_threads, oop=oop, num_bins=1000, output_file_name=save_path)\n",
    "    \n",
    "    # Calculate I(tth) if requested.\n",
    "    if intensity_vs_tth:\n",
    "        intensity, tth = experiment.intensity_vs_tth(\n",
    "        num_threads, oop=oop, num_bins=1000, output_file_name=save_path)\n",
    "\n",
    "    # Finally, print that it's finished We'll use this to work out when the\n",
    "    # processing is done.\n",
    "    print(\"PROCESSING FINISHED.\")\n",
    "\n",
    "class DontContinue(Exception):\n",
    "    \"\"\"Raise to stop processing on the cluster at this cell\"\"\"\n",
    "\n",
    "raise DontContinue(\"Processing complete!!\\n\"\n",
    "                   \"This is intentionally raised to stop the processing. \"\n",
    "                   \"Never worry about the presence of this 'error'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**ESSENTIAL**\n",
    "\n",
    "This is the cell that you should execute to run this notebook on the cluster.\n",
    "\n",
    "DO NOT EXECUTE THIS MULTIPLE TIMES. IT WILL SUBMIT MULTIPLE JOBS TO THE CLUSTER.\n",
    "PLEASE BE RESPONSIBLE.\n",
    "\"\"\"\n",
    "# We need this to grab the current working directory.\n",
    "import os\n",
    "\n",
    "# We'll need this to run the program that will submit the cluster job.\n",
    "# This module isn't needed for the calculation itself, which is why it is\n",
    "# imported here.\n",
    "import subprocess\n",
    "\n",
    "# First, we save this as \"map.py\". Make sure it doesn't already exist.\n",
    "try:\n",
    "    os.remove(\"map.py\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# Convert this notebook to a python script in our home directory.\n",
    "!jupyter nbconvert --to script map.ipynb\n",
    "\n",
    "\n",
    "# Submit the job, which in turn loads the Hamilton module and runs:\n",
    "# qsub -pe smp 40 -l m_mem_free=2.5G -P i07 cluster_job.sh\n",
    "subprocess.run(\n",
    "    [\"sh\", \"/dls_sw/apps/fast_rsm/current/scripts/cluster_sub.sh\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following cells contain convenience tools for e.g. interacting with and\n",
    "visualising data.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**RUN THIS**\n",
    "\n",
    "You should run this cell, but don't worry about its contents.\n",
    "\n",
    "This cell just defines a few handy functions that will be used below.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def most_recent_cluster_output():\n",
    "    \"\"\"\n",
    "    Returns the filename of the most recent cluster stdout output.\n",
    "    \"\"\"\n",
    "    # Get all the cluster job files that have been created.\n",
    "    files = [x for x in os.listdir() if x.startswith(\"cluster_job.sh.o\")]\n",
    "    numbers = [int(x[16:]) for x in files]\n",
    "\n",
    "    # Work out which cluster job is the most recent.\n",
    "    most_recent_job_no = np.max(numbers)\n",
    "    most_recent_file = \"\"\n",
    "    for file in files:\n",
    "        if str(most_recent_job_no) in file:\n",
    "            most_recent_file = file\n",
    "\n",
    "    return most_recent_file\n",
    "\n",
    "\n",
    "def most_recent_cluster_error():\n",
    "    \"\"\"\n",
    "    Returns the filename of the most recent cluster stderr output.\n",
    "    \"\"\"\n",
    "    # Get all the cluster job files that have been created.\n",
    "    files = [x for x in os.listdir() if x.startswith(\"cluster_job.sh.e\")]\n",
    "    numbers = [int(x[16:]) for x in files]\n",
    "\n",
    "    # Work out which cluster job is the most recent.\n",
    "    most_recent_job_no = np.max(numbers)\n",
    "    most_recent_file = \"\"\n",
    "    for file in files:\n",
    "        if str(most_recent_job_no) in file:\n",
    "            most_recent_file = file\n",
    "\n",
    "    return most_recent_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Are we nearly there yet?\n",
    "\n",
    "Executing this cell tells you if your most recent cluster submission has\n",
    "finished executing.\n",
    "\"\"\"\n",
    "\n",
    "most_recent_file = most_recent_cluster_output()\n",
    "\n",
    "# Open that file, and see if it ends in \"Finished.\"\n",
    "with open(most_recent_file, 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "    # Check if there's nothing in the file yet.\n",
    "    if len(lines) == 0:\n",
    "        print(\"Processing either not started or crashed.\")\n",
    "    last_line = lines[-1].strip()\n",
    "    if last_line.startswith(\"PROCESSING FINISHED.\"):\n",
    "        print(\"Most recent processing has completed.\")\n",
    "    else:\n",
    "        print(\n",
    "            \"Processing job has started on the cluster, but isn't finished. \"\n",
    "            \"It could have crashed, or it could still be running.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell contains functions that you can use to read the most recent cluster\n",
    "output and error logs.\n",
    "\"\"\"\n",
    "\n",
    "def print_recent_output():\n",
    "    \"\"\"Prints the most recent cluster output log file.\"\"\"\n",
    "    with open(most_recent_cluster_output(), 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "\n",
    "def print_recent_error():\n",
    "    \"\"\"Prints the most recent cluster error log file.\"\"\"\n",
    "    with open(most_recent_cluster_error(), 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "\n",
    "print(\"Cluster stderr (error logs) below:\")\n",
    "print_recent_error()\n",
    "print(\"\\n\\n\\nCluster stdout (output logs) below:\")\n",
    "print_recent_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell computes averages over your data.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('fast_rsm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d3d0365b0cf09d8aafe0187e5e70cb1582c70373590192715db7909432628a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
