{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "First we need to import some stuff. Feel free to ignore this cell.\n",
    "\n",
    "If you're interested, each import has an associated comment that explains why\n",
    "the import is useful/necessary.\n",
    "\"\"\"\n",
    "\n",
    "# Used for constructing paths.\n",
    "from pathlib import Path\n",
    "# Used to work out how much time the processing took.\n",
    "from time import time\n",
    "\n",
    "# Essential for all mathematical operations we'll be carrying out.\n",
    "import numpy as np\n",
    "\n",
    "# diffraction_utils is a library developed at Diamond by Richard Brearton\n",
    "# (richard.brearton@diamond.ac.uk) to ease the task of parsing data files and\n",
    "# carrying out some common calculations. Here, we'll be using it to define\n",
    "# frames of reference, and parse nexus files.\n",
    "from diffraction_utils import Frame, I07Nexus\n",
    "\n",
    "# The following imports are required for the core of the calculation code, also\n",
    "# written by Richard Brearton (richard.brearton@diamond.ac.uk).\n",
    "# These functions are used to calculate the region of reciprocal space that was\n",
    "# sampled during the scan, and to calculate the step size we should use to\n",
    "# achieve the file size requested.\n",
    "from fast_rsm.meta_analysis import find_q_bounds, get_step_from_filesize\n",
    "# This is the central Scan object, which stores all the logic related to\n",
    "# individual scans.\n",
    "from fast_rsm.scan import Scan\n",
    "# This function will be used to save our data so that we can open it in\n",
    "# Paraview.\n",
    "from fast_rsm.writing import linear_bin_to_vtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell requires action! Make sure you set all of the variables defined here.\n",
    "\"\"\"\n",
    "\n",
    "# What was your scattering geometry/how was your sample mounted? Options are\n",
    "# 'horizontal', 'vertical' and 'DCD'.\n",
    "setup = 'horizontal'\n",
    "\n",
    "# The experiment number, used to work out where your data is stored.\n",
    "experiment_number = 'si32333-1'\n",
    "\n",
    "# The sub-directory containing your experimental data. Leave as None if unused.\n",
    "# Otherwise, if the data was stored in a subdirectory called \"day_1\", e.g. \n",
    "#   /dls/i07/data/2022/si32333-1/day_1/\n",
    "# then you should use:\n",
    "#   data_sub_directory = \"day_1\"\n",
    "data_sub_directory = None\n",
    "\n",
    "# The year the experiment took place.\n",
    "year = 2022\n",
    "\n",
    "# The scan numbers of the scans that we want to use to produce this reciprocal\n",
    "# space map. For example, the default value of scan_numbers shows how to specify\n",
    "# every scan between number 421772 and 421778 inclusive, but skipping scan\n",
    "# number 421776.\n",
    "scan_numbers = [421772, 421773, 421774, 421775, 421777, 421778]\n",
    "\n",
    "# Uncomment the following to set scan_numbers equal to every scan number between\n",
    "# scan_start and scan_stop:\n",
    "# scan_start = 421772\n",
    "# scan_stop = 421775\n",
    "# scan_numbers = list(range(scan_start, scan_stop + 1))\n",
    "\n",
    "# The beam centre, as can be read out from GDA, in pixel_x, pixel_y. If your\n",
    "# map looks wacky, you probably cocked this up.\n",
    "beam_centre = (769, 1330)\n",
    "\n",
    "# The distance between the sample and the detector (or, if using the DCD, the\n",
    "# distance between the receiving slit and the detector). Units of meters.\n",
    "detector_distance = 485e-3\n",
    "\n",
    "# The frame/coordinate system you want the map to be carried out in. \n",
    "# Options for frame_name argument are:\n",
    "#     Frame.hkl     (map into hkl space - requires UB matrix in nexus file)\n",
    "#     Frame.sample_holder   (standard map into 1/Ã…)\n",
    "#     Frame.lab     (map into frame attached to lab. I dont think you want this)\n",
    "# \n",
    "# Options for coordinates argument are:\n",
    "#     Frame.cartesian   (normal cartesian coords: hkl, Qx Qy Qz, etc.)\n",
    "#     Frame.polar       (cylindrical polar with cylinder axis along l/Qz)\n",
    "# \n",
    "# Frame.polar will give an output like a more general version of PyFAI.\n",
    "# Frame.cartesian is for hkl maps and Qx/Qy/Qz. Any combination of frame_name\n",
    "# and coordinates will work, so try them out; get a feel for them.\n",
    "frame_name = Frame.hkl\n",
    "coordinates = Frame.cartesian\n",
    "\n",
    "# Ignore pixels with an intensity below this value. If you don't want to ignore\n",
    "# any pixels, then set min_intensity = None. This is ueful for dynamically\n",
    "# creating masks.\n",
    "min_intensity = None\n",
    "\n",
    "# How large would you like your output file to be, in MB? 100MB normally gives\n",
    "# very good resolution without sacrificing performance. If you want something\n",
    "# higher resolution, feel free, but be aware that the performance of the map and\n",
    "# the analysis will start to suffer above around 1GB.\n",
    "output_file_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell prepares the calculation. You probably shouldn't change anything here\n",
    "unless you know what you're doing.\n",
    "\"\"\"\n",
    "\n",
    "# Max number of cores on a Hamilton cluster node.\n",
    "num_threads = 40\n",
    "\n",
    "# Work out where the data is. \n",
    "data_dir = Path(f\"/dls/i07/data/{year}/{experiment_number}/\")\n",
    "\n",
    "# Store this for later.\n",
    "processing_dir = data_dir / \"processing\"\n",
    "if data_sub_directory is not None:\n",
    "    data_dir /= Path(data_sub_directory)\n",
    "\n",
    "# You can make this what you like, but note that same datetime data will be\n",
    "# inserted to ensure that your output file has a unique name.\n",
    "save_name = \"mapped_scan_\"\n",
    "\n",
    "# Construct the Frame object from the user's preferred frame/coords.\n",
    "map_frame = Frame(frame_name=frame_name, coordinates=coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell contains all of the logic for running the calculation. You shouldn't\n",
    "run this on your local computer, it'll either raise an exception or take\n",
    "forever.\n",
    "\"\"\"\n",
    "\n",
    "# These keep track of where the processing output of individual scans will be\n",
    "# saved.\n",
    "data_file_names = []\n",
    "normalisation_file_names = []\n",
    "\n",
    "# First work out start/stop/step.\n",
    "t1 = time()\n",
    "print(\"Calculating q-bounds...\\r\", end='')\n",
    "starts, stops = [], []\n",
    "for scan_number in scan_numbers:\n",
    "    print(f\"Calculating q-bounds for scan number {scan_number}.\\r\", end='')\n",
    "    path_to_nx = data_dir / f\"{scan_number}.nxs\"\n",
    "    scan = Scan.from_i07(path_to_nx, beam_centre, detector_distance, setup,\n",
    "                            [0, 1, 0], path_to_nx)\n",
    "    start, stop = find_q_bounds(scan, map_frame)\n",
    "    starts.append(start)\n",
    "    stops.append(stop)\n",
    "\n",
    "starts, stops = np.array(starts), np.array(stops)\n",
    "start, stop = np.min(starts, axis=0), np.max(stops, axis=0)\n",
    "step = get_step_from_filesize(start, stop, output_file_size)\n",
    "\n",
    "print(f\"Binning reciprocal space from {start} to {stop} in steps of \" +\n",
    "      f\"{step}.\")\n",
    "\n",
    "print(f\"Took {(time() - t1)*1000} ms to calculate q bounds.\")\n",
    "\n",
    "# Now that we've worked out where we are in reciprocal space, actually do\n",
    "# the mapping.\n",
    "for scan_number in scan_numbers:\n",
    "    t1 = time()\n",
    "    path_to_nx = data_dir / f\"{scan_number}.nxs\"\n",
    "\n",
    "    scan = Scan.from_i07(path_to_nx, beam_centre, detector_distance, setup,\n",
    "                            [0, 1, 0], path_to_nx)\n",
    "\n",
    "    i07nexus = I07Nexus(path_to_nx)\n",
    "    print(f\"Beginning mapping of the {i07nexus.scan_length} images in \"\n",
    "            f\"scan number {scan_number} with {num_threads} cores.\")\n",
    "    rsmap, counts = scan.binned_reciprocal_space_map(\n",
    "        map_frame, start, stop, step, min_intensity, num_threads)\n",
    "\n",
    "    t2 = time()\n",
    "    time_taken = t2-t1\n",
    "    time_per_image = time_taken/scan.metadata.data_file.scan_length*1000\n",
    "\n",
    "    print(f\"Time taken per image: {time_per_image} ms\")\n",
    "    print(f\"Time taken to process whole scan: {time_taken} s\")\n",
    "\n",
    "    # Save the map and the normalisation separately.\n",
    "    save_data = save_name + str(scan_number)\n",
    "    save_norm = save_name + f\"normalisation_{scan_number}\"\n",
    "    data_file_names.append(save_data)\n",
    "    normalisation_file_names.append(save_norm)\n",
    "    np.save(save_data, rsmap)\n",
    "    np.save(save_norm, counts)\n",
    "\n",
    "print(\"Mapping completed. Commencing normalisation procedure...\")\n",
    "\n",
    "# Now iterate over all of the maps and normalise the total map.\n",
    "total_map = np.zeros_like(rsmap, dtype=np.float32)\n",
    "total_counts = np.zeros_like(counts, dtype=np.float32)\n",
    "for i, map_name in enumerate(data_file_names):\n",
    "    total_map += np.load(map_name + '.npy')\n",
    "    total_counts += np.load(normalisation_file_names[i] + '.npy')\n",
    "\n",
    "normalised_map = total_map / total_counts\n",
    "vtk_name = data_file_names[0] + \"_normalised\"\n",
    "linear_bin_to_vtk(normalised_map, data_file_names[0], start, stop, step)\n",
    "\n",
    "print(\"Map normalised and saved to vtk. Exiting...\")\n",
    "exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'output_name' matched no files\n",
      "[NbConvertApp] Converting notebook map.ipynb to script\n",
      "[NbConvertApp] Writing 8493 bytes to map.py\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the cell that you should execute to run this notebook on the cluster.\n",
    "\"\"\"\n",
    "\n",
    "# We'll need this to run the program that will submit the cluster job.\n",
    "# This module isn't needed for the calculation itself, which is why it is\n",
    "# imported here.\n",
    "import subprocess\n",
    "\n",
    "# Prepare the fast_rsm python environment.\n",
    "\n",
    "# Convert this notebook to a python script.\n",
    "output_name = \"mapper.py\"\n",
    "!jupyter nbconvert --to script map.ipynb map.py\n",
    "\n",
    "# Now actually submit it to the cluster. TODO: work out where map.py gets saved.\n",
    "map_script_path = \"\"\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following cells contain tools for interacting with and visualising data.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('fast_rsm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d3d0365b0cf09d8aafe0187e5e70cb1582c70373590192715db7909432628a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
