{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**OPTIONAL/IGNORE**\n",
    "\n",
    "First we need to import some stuff. Feel free to ignore this cell.\n",
    "\n",
    "If you're interested, each import has an associated comment that explains why\n",
    "the import is useful/necessary.\n",
    "\"\"\"\n",
    "\n",
    "# Needed for various filesystem tasks (os.exists etc.)\n",
    "import os\n",
    "# Used for checking how many cores are available for processing.\n",
    "import multiprocessing\n",
    "# Used for constructing paths.\n",
    "from pathlib import Path\n",
    "\n",
    "# Essential for all mathematical operations we'll be carrying out.\n",
    "import numpy as np\n",
    "\n",
    "# diffraction_utils is a library developed at Diamond by Richard Brearton\n",
    "# (richard.brearton@diamond.ac.uk) to ease the task of parsing data files and\n",
    "# carrying out some common calculations. Here, we'll be using it to define\n",
    "# frames of reference, and parse nexus files.\n",
    "from diffraction_utils import Frame\n",
    "\n",
    "# The following imports are required for the core of the calculation code, also\n",
    "# written by Richard Brearton (richard.brearton@diamond.ac.uk).\n",
    "# This is the central Experiment object, which stores all the logic related to\n",
    "# mapping the experiment.\n",
    "from fast_rsm.experiment import Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**ESSENTIAL**\n",
    "\n",
    "This cell requires action! Make sure you set all of the variables defined here.\n",
    "\"\"\"\n",
    "\n",
    "# What was your scattering geometry/how was your sample mounted? Options are\n",
    "# 'horizontal', 'vertical' and 'DCD'.\n",
    "setup = 'vertical'\n",
    "\n",
    "# The experiment number, used to work out where your data is stored.\n",
    "experiment_number = 'si31695-1'\n",
    "\n",
    "# The sub-directory containing your experimental data. Leave as None if unused.\n",
    "# Otherwise, if the data was stored in a subdirectory called \"day_1\", e.g.\n",
    "#   /dls/i07/data/2022/si32333-1/day_1/\n",
    "# then you should use:\n",
    "#   data_sub_directory = \"day_1\"\n",
    "data_sub_directory = \"Ag100clean/\"\n",
    "\n",
    "# The year the experiment took place.\n",
    "year = 2022\n",
    "\n",
    "# The scan numbers of the scans that we want to use to produce this reciprocal\n",
    "# space map. For example, the default value of scan_numbers shows how to specify\n",
    "# every scan between number 421772 and 421778 inclusive, but skipping scan\n",
    "# number 421776.\n",
    "scan_numbers = [445500, 445501, 445502]\n",
    "\n",
    "# Uncomment the following to set scan_numbers equal to every scan number between\n",
    "# scan_start and scan_stop (inclusive of scan_stop):\n",
    "# scan_start = 439168\n",
    "# scan_stop = 439176\n",
    "# scan_numbers = list(range(scan_start, scan_stop + 1))\n",
    "\n",
    "# The beam centre, as can be read out from GDA, in pixel_x, pixel_y. If your\n",
    "# map looks wacky, you probably cocked this up.\n",
    "beam_centre = (242, 95)\n",
    "\n",
    "# The distance between the sample and the detector (or, if using the DCD, the\n",
    "# distance between the receiving slit and the detector). Units of meters.\n",
    "detector_distance = 930e-3\n",
    "\n",
    "# The frame/coordinate system you want the map to be carried out in.\n",
    "# Options for frame_name argument are:\n",
    "#     Frame.hkl     (map into hkl space - requires UB matrix in nexus file)\n",
    "#     Frame.sample_holder   (standard map into 1/Ã…)\n",
    "#     Frame.lab     (map into frame attached to lab. I dont think you want this)\n",
    "#\n",
    "# Options for coordinates argument are:\n",
    "#     Frame.cartesian   (normal cartesian coords: hkl, Qx Qy Qz, etc.)\n",
    "#     Frame.polar       (cylindrical polar with cylinder axis along l/Qz)\n",
    "#\n",
    "# Frame.polar will give an output like a more general version of PyFAI.\n",
    "# Frame.cartesian is for hkl maps and Qx/Qy/Qz. Any combination of frame_name\n",
    "# and coordinates will work, so try them out; get a feel for them.\n",
    "frame_name = Frame.hkl\n",
    "coordinates = Frame.cartesian\n",
    "\n",
    "# Ignore pixels with an intensity below this value. If you don't want to ignore\n",
    "# any pixels, then set min_intensity = None. This is useful for dynamically\n",
    "# creating masks (which, in retrospect... might not actually be useful).\n",
    "min_intensity = None\n",
    "\n",
    "# How large would you like your output file to be, in MB? 100MB normally gives\n",
    "# very good resolution without sacrificing performance. If you want something\n",
    "# higher resolution, feel free, but be aware that the performance of the map and\n",
    "# the analysis will start to suffer above around 1GB.\n",
    "# Max file size is 2GB (2000MB).\n",
    "output_file_size = 100\n",
    "\n",
    "# What do you want to do? Processing time is linear in the number of these you\n",
    "# set to True. I could definitely make that cleverer in the future, though.\n",
    "generate_vtk = True # This is for loading into paraview.\n",
    "intensity_vs_Q = False # I vs |Q|\n",
    "intensity_vs_l = False # I vs l\n",
    "intensity_vs_tth = False # I vs total scattered two theta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**OPTIONAL/IGNORE**\n",
    "This cell prepares the calculation. You probably shouldn't change anything here\n",
    "unless you know what you're doing.\n",
    "\"\"\"\n",
    "\n",
    "# Which synchrotron axis should become the out-of-plane (001) direction.\n",
    "# Defaults to 'y'; can be 'x', 'y' or 'z'.\n",
    "if setup == 'vertical':\n",
    "    oop = 'x'\n",
    "elif setup == 'horizontal':\n",
    "    oop = 'y'\n",
    "elif setup == 'DCD':\n",
    "    oop = 'y'\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Setup not recognised. Must be 'vertical', 'horizontal' or 'DCD.\")\n",
    "\n",
    "if output_file_size > 2000:\n",
    "    raise ValueError(\"output_file_size must not exceed 2000. \"\n",
    "                     f\"Value received was {output_file_size}.\")\n",
    "\n",
    "# Max number of cores available for processing.\n",
    "num_threads = multiprocessing.cpu_count()\n",
    "\n",
    "# Work out where the data is.\n",
    "data_dir = Path(f\"/dls/i07/data/{year}/{experiment_number}/\")\n",
    "# data_dir = Path(f\"/Users/richard/Data/i07/{experiment_number}/\")\n",
    "\n",
    "# Store this for later.\n",
    "processing_dir = data_dir / \"processing\"\n",
    "if data_sub_directory is not None:\n",
    "    data_dir /= Path(data_sub_directory)\n",
    "\n",
    "# Here we calculate a sensible file name that hasn't been taken.\n",
    "i = 0\n",
    "save_file_name = f\"mapped_scan_{scan_numbers[0]}_{i}\"\n",
    "save_path = processing_dir / save_file_name\n",
    "# Make sure that this name hasn't been used in the past.\n",
    "while os.path.exists(save_path):\n",
    "    i += 1\n",
    "    save_file_name = f\"mapped_scan_{scan_numbers[0]}_{i}\"\n",
    "    save_path = processing_dir / save_file_name\n",
    "\n",
    "    if i > 1e7:\n",
    "        raise ValueError(\n",
    "            \"Either you tried to save this file 10000000 times, or something \"\n",
    "            \"went wrong. I'm going with the latter, but exiting out anyway.\")\n",
    "\n",
    "\n",
    "# Work out the paths to each of the nexus files. Store as pathlib.Path objects.\n",
    "nxs_paths = [data_dir / f\"i07-{x}.nxs\" for x in scan_numbers]\n",
    "\n",
    "# Construct the Frame object from the user's preferred frame/coords.\n",
    "map_frame = Frame(frame_name=frame_name, coordinates=coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**TEMPORARILY REQUIRED**\n",
    "\n",
    "This cell contains all of the logic for running the calculation. You shouldn't\n",
    "run this on your local computer, it'll either raise an exception or take\n",
    "forever.\n",
    "\n",
    "For now, pixel masking logic lives here. I'll move this to the first cell later,\n",
    "so that there's only one cell that you need to interact with.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # We always need to prepare the experiment.\n",
    "    experiment = Experiment.from_i07_nxs(\n",
    "        nxs_paths, beam_centre, detector_distance, setup)\n",
    "\n",
    "    # There's a hot pixel that needs masking. Comment this out if you don't want\n",
    "    # to mask anything.\n",
    "    experiment.mask_pixels((83, 233))\n",
    "\n",
    "    # These example nexus data files are broken. The data needs to be backed up\n",
    "    # from .dat files, which contains the motor positions. Comment this out in\n",
    "    # the likely event that you don't need to do this.\n",
    "    for i, scan in enumerate(experiment.scans):\n",
    "        dat_path = data_dir / data_dir / f\"{scan_numbers[i]}.dat\"\n",
    "        scan.metadata.data_file.populate_data_from_dat(dat_path)\n",
    "\n",
    "    # Uncomment to run and save a binned reciprocal space map.\n",
    "    if generate_vtk:\n",
    "        experiment.binned_reciprocal_space_map(\n",
    "        num_threads, map_frame, output_file_size=output_file_size, oop=oop,\n",
    "        output_file_name=save_file_name)\n",
    "\n",
    "    # Uncomment to get intensity vs L.\n",
    "    if intensity_vs_l:\n",
    "        intensity, l = experiment.intensity_vs_l(\n",
    "        num_threads, oop=oop, output_file_name=save_file_name)\n",
    "\n",
    "    # Uncomment to get intensity vs |Q|.\n",
    "    if intensity_vs_Q:\n",
    "        intensity, q = experiment.intensity_vs_q(\n",
    "        num_threads, oop=oop, num_bins=1000, output_file_name=save_file_name)\n",
    "    \n",
    "    # Uncomment to get intensity vs 2theta.\n",
    "    if intensity_vs_tth:\n",
    "        intensity, tth = experiment.intensity_vs_tth(\n",
    "        num_threads, oop=oop, num_bins=1000, output_file_name=save_file_name)\n",
    "\n",
    "    # Finally, print that it's finished We'll use this to work out when the\n",
    "    # processing is done.\n",
    "    print(\"PROCESSING FINISHED.\")\n",
    "\n",
    "class DontContinue(Exception):\n",
    "    \"\"\"Raise to stop processing on the cluster at this cell\"\"\"\n",
    "\n",
    "raise DontContinue(\"Processing complete!!\\n\"\n",
    "                   \"This is intentionally raised to stop the processing. \"\n",
    "                   \"Never worry about the presence of this 'error'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**ESSENTIAL**\n",
    "\n",
    "This is the cell that you should execute to run this notebook on the cluster.\n",
    "\n",
    "DO NOT EXECUTE THIS MULTIPLE TIMES. IT WILL SUBMIT MULTIPLE JOBS TO THE CLUSTER.\n",
    "PLEASE BE RESPONSIBLE.\n",
    "\"\"\"\n",
    "\n",
    "# We need this to grab the current working directory.\n",
    "import os\n",
    "\n",
    "# We'll need this to run the program that will submit the cluster job.\n",
    "# This module isn't needed for the calculation itself, which is why it is\n",
    "# imported here.\n",
    "import subprocess\n",
    "\n",
    "# First, we save this as \"map.py\". Make sure it doesn't already exist.\n",
    "try:\n",
    "    os.remove(\"map.py\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# Convert this notebook to a python script in our home directory.\n",
    "!jupyter nbconvert --to script map.ipynb\n",
    "\n",
    "# Submit the job, which in turn loads the Hamilton module and runs:\n",
    "# qsub -pe smp 40 -l m_mem_free=2.5G -P i07 cluster_job.sh\n",
    "subprocess.run([\"sh\", \"/dls_sw/apps/fast_rsm/current/scripts/cluster_sub.sh\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following cells contain convenience tools for e.g. interacting with and\n",
    "visualising data.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**IGNORE**\n",
    "\n",
    "This cell just defines a couple of handy functions. Feel free to ignore.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def most_recent_cluster_output():\n",
    "    \"\"\"\n",
    "    Returns the filename of the most recent cluster stdout output.\n",
    "    \"\"\"\n",
    "    # Get all the cluster job files that have been created.\n",
    "    files = [x for x in os.listdir() if x.startswith(\"cluster_job.sh.o\")]\n",
    "    numbers = [int(x[16:]) for x in files]\n",
    "\n",
    "    # Work out which cluster job is the most recent.\n",
    "    most_recent_job_no = np.max(numbers)\n",
    "    most_recent_file = \"\"\n",
    "    for file in files:\n",
    "        if str(most_recent_job_no) in file:\n",
    "            most_recent_file = file\n",
    "\n",
    "    return most_recent_file\n",
    "\n",
    "\n",
    "def most_recent_cluster_error():\n",
    "    \"\"\"\n",
    "    Returns the filename of the most recent cluster stderr output.\n",
    "    \"\"\"\n",
    "    # Get all the cluster job files that have been created.\n",
    "    files = [x for x in os.listdir() if x.startswith(\"cluster_job.sh.e\")]\n",
    "    numbers = [int(x[16:]) for x in files]\n",
    "\n",
    "    # Work out which cluster job is the most recent.\n",
    "    most_recent_job_no = np.max(numbers)\n",
    "    most_recent_file = \"\"\n",
    "    for file in files:\n",
    "        if str(most_recent_job_no) in file:\n",
    "            most_recent_file = file\n",
    "\n",
    "    return most_recent_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Are we nearly there yet?\n",
    "\n",
    "Executing this cell tells you if your most recent cluster submission has\n",
    "finished executing.\n",
    "\"\"\"\n",
    "\n",
    "most_recent_file = most_recent_cluster_output()\n",
    "\n",
    "# Open that file, and see if it ends in \"Finished.\"\n",
    "with open(most_recent_file, 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "    # Check if there's nothing in the file yet.\n",
    "    if len(lines) == 0:\n",
    "        print(\"Processing either not started or crashed.\")\n",
    "    last_line = lines[-1].strip()\n",
    "    if last_line.startswith(\"PROCESSING FINISHED.\"):\n",
    "        print(\"Most recent processing has completed.\")\n",
    "    else:\n",
    "        print(\"Most recent processing has not yet completed.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell contains functions that you can use to read the most recent cluster\n",
    "output and error logs.\n",
    "\"\"\"\n",
    "\n",
    "def print_recent_output():\n",
    "    \"\"\"Prints the most recent cluster output log file.\"\"\"\n",
    "    with open(most_recent_cluster_output(), 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "\n",
    "def print_recent_error():\n",
    "    \"\"\"Prints the most recent cluster error log file.\"\"\"\n",
    "    with open(most_recent_cluster_error(), 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "\n",
    "print_recent_error()\n",
    "print_recent_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('fast_rsm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d3d0365b0cf09d8aafe0187e5e70cb1582c70373590192715db7909432628a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
