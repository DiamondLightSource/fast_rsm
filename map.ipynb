{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**OPTIONAL/IGNORE**\n",
    "\n",
    "First we need to import some stuff. Feel free to ignore this cell.\n",
    "\n",
    "If you're interested, each import has an associated comment that explains why\n",
    "the import is useful/necessary.\n",
    "\"\"\"\n",
    "\n",
    "# Used for checking how many cores are available for processing.\n",
    "import multiprocessing\n",
    "# Used for constructing paths.\n",
    "from pathlib import Path\n",
    "# Used to work out how much time the processing took.\n",
    "from time import time\n",
    "\n",
    "# Essential for all mathematical operations we'll be carrying out.\n",
    "import numpy as np\n",
    "\n",
    "# diffraction_utils is a library developed at Diamond by Richard Brearton\n",
    "# (richard.brearton@diamond.ac.uk) to ease the task of parsing data files and\n",
    "# carrying out some common calculations. Here, we'll be using it to define\n",
    "# frames of reference, and parse nexus files.\n",
    "from diffraction_utils import Frame, I07Nexus\n",
    "\n",
    "# The following imports are required for the core of the calculation code, also\n",
    "# written by Richard Brearton (richard.brearton@diamond.ac.uk).\n",
    "# These functions are used to calculate the region of reciprocal space that was\n",
    "# sampled during the scan, and to calculate the step size we should use to\n",
    "# achieve the file size requested.\n",
    "from fast_rsm.meta_analysis import get_step_from_filesize\n",
    "# This is the central Experiment object, which stores all the logic related to\n",
    "# mapping the experiment.\n",
    "from fast_rsm.experiment import Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**ESSENTIAL**\n",
    "\n",
    "This cell requires action! Make sure you set all of the variables defined here.\n",
    "\"\"\"\n",
    "\n",
    "# What was your scattering geometry/how was your sample mounted? Options are\n",
    "# 'horizontal', 'vertical' and 'DCD'.\n",
    "setup = 'vertical'\n",
    "\n",
    "# The experiment number, used to work out where your data is stored.\n",
    "experiment_number = 'si31695-1'\n",
    "\n",
    "# The sub-directory containing your experimental data. Leave as None if unused.\n",
    "# Otherwise, if the data was stored in a subdirectory called \"day_1\", e.g.\n",
    "#   /dls/i07/data/2022/si32333-1/day_1/\n",
    "# then you should use:\n",
    "#   data_sub_directory = \"day_1\"\n",
    "data_sub_directory = \"Ag100clean/\"\n",
    "\n",
    "# The year the experiment took place.\n",
    "year = 2022\n",
    "\n",
    "# The scan numbers of the scans that we want to use to produce this reciprocal\n",
    "# space map. For example, the default value of scan_numbers shows how to specify\n",
    "# every scan between number 421772 and 421778 inclusive, but skipping scan\n",
    "# number 421776.\n",
    "scan_numbers = [445500, 445501, 445502]\n",
    "\n",
    "# Uncomment the following to set scan_numbers equal to every scan number between\n",
    "# scan_start and scan_stop (inclusive of scan_stop):\n",
    "# scan_start = 439168\n",
    "# scan_stop = 439176\n",
    "# scan_numbers = list(range(scan_start, scan_stop + 1))\n",
    "\n",
    "# The beam centre, as can be read out from GDA, in pixel_x, pixel_y. If your\n",
    "# map looks wacky, you probably cocked this up.\n",
    "beam_centre = (242, 95)\n",
    "\n",
    "# The distance between the sample and the detector (or, if using the DCD, the\n",
    "# distance between the receiving slit and the detector). Units of meters.\n",
    "detector_distance = 930e-3\n",
    "\n",
    "# The frame/coordinate system you want the map to be carried out in.\n",
    "# Options for frame_name argument are:\n",
    "#     Frame.hkl     (map into hkl space - requires UB matrix in nexus file)\n",
    "#     Frame.sample_holder   (standard map into 1/Ã…)\n",
    "#     Frame.lab     (map into frame attached to lab. I dont think you want this)\n",
    "#\n",
    "# Options for coordinates argument are:\n",
    "#     Frame.cartesian   (normal cartesian coords: hkl, Qx Qy Qz, etc.)\n",
    "#     Frame.polar       (cylindrical polar with cylinder axis along l/Qz)\n",
    "#\n",
    "# Frame.polar will give an output like a more general version of PyFAI.\n",
    "# Frame.cartesian is for hkl maps and Qx/Qy/Qz. Any combination of frame_name\n",
    "# and coordinates will work, so try them out; get a feel for them.\n",
    "frame_name = Frame.hkl\n",
    "coordinates = Frame.cartesian\n",
    "\n",
    "# Ignore pixels with an intensity below this value. If you don't want to ignore\n",
    "# any pixels, then set min_intensity = None. This is useful for dynamically\n",
    "# creating masks (which, in retrospect... might not actually be useful).\n",
    "min_intensity = None\n",
    "\n",
    "# How large would you like your output file to be, in MB? 100MB normally gives\n",
    "# very good resolution without sacrificing performance. If you want something\n",
    "# higher resolution, feel free, but be aware that the performance of the map and\n",
    "# the analysis will start to suffer above around 1GB.\n",
    "# Max file size is 2GB (2000MB).\n",
    "output_file_size = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**OPTIONAL/IGNORE**\n",
    "This cell prepares the calculation. You probably shouldn't change anything here\n",
    "unless you know what you're doing.\n",
    "\"\"\"\n",
    "\n",
    "# Which synchrotron axis should become the out-of-plane (001) direction.\n",
    "# Defaults to 'y'; can be 'x', 'y' or 'z'.\n",
    "if setup == 'vertical':\n",
    "    oop = 'x'\n",
    "elif setup == 'horizontal':\n",
    "    oop = 'y'\n",
    "elif setup == 'DCD':\n",
    "    oop = 'y'\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Setup not recognised. Must be 'vertical', 'horizontal' or 'DCD.\")\n",
    "\n",
    "if output_file_size > 2000:\n",
    "    raise ValueError(\"output_file_size must not exceed 2000. \"\n",
    "                     f\"Value received was {output_file_size}.\")\n",
    "\n",
    "# Max number of cores available for processing.\n",
    "num_threads = multiprocessing.cpu_count()\n",
    "\n",
    "# Work out where the data is.\n",
    "data_dir = Path(f\"/dls/i07/data/{year}/{experiment_number}/\")\n",
    "# data_dir = Path(f\"/Users/richard/Data/i07/{experiment_number}/\")\n",
    "\n",
    "# Store this for later.\n",
    "processing_dir = data_dir / \"processing\"\n",
    "if data_sub_directory is not None:\n",
    "    data_dir /= Path(data_sub_directory)\n",
    "\n",
    "# You can make this what you like, but note that same datetime data will be\n",
    "# inserted to ensure that your output file has a unique name.\n",
    "save_name = \"mapped_scan_\"\n",
    "\n",
    "# Work out the paths to each of the nexus files. Store as pathlib.Path objects.\n",
    "nxs_paths = [data_dir / f\"i07-{x}.nxs\" for x in scan_numbers]\n",
    "\n",
    "# Construct the Frame object from the user's preferred frame/coords.\n",
    "map_frame = Frame(frame_name=frame_name, coordinates=coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**REQUIRED**\n",
    "\n",
    "This cell contains all of the logic for running the calculation. You shouldn't\n",
    "run this on your local computer, it'll either raise an exception or take\n",
    "forever.\n",
    "\n",
    "Uncomment the routines that you would like to run.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # We always need to prepare the experiment.\n",
    "    experiment = Experiment.from_i07_nxs(\n",
    "        nxs_paths, beam_centre, detector_distance, setup)\n",
    "\n",
    "    # There's a hot pixel that needs masking. Comment this out if you don't want\n",
    "    # to mask anything.\n",
    "    experiment.mask_pixels((83, 233))\n",
    "\n",
    "    # These example nexus data files are broken. The data needs to be backed up\n",
    "    # from .dat files, which contains the motor positions. Comment this out in\n",
    "    # the likely event that you don't need to do this.\n",
    "    for i, scan in enumerate(experiment.scans):\n",
    "        dat_path = data_dir / data_dir / f\"{scan_numbers[i]}.dat\"\n",
    "        scan.metadata.data_file.populate_data_from_dat(dat_path)\n",
    "\n",
    "    # Uncomment to run and save a binned reciprocal space map.\n",
    "    # experiment.binned_reciprocal_space_map(\n",
    "    #     num_threads, map_frame, output_file_size=output_file_size, oop=oop)\n",
    "\n",
    "    # Uncomment to get intensity vs L.\n",
    "    # intensity, l = experiment.intensity_vs_l(num_threads, oop=oop)\n",
    "\n",
    "    # Uncomment to get intensity vs |Q|.\n",
    "    # intensity, q = experiment.intensity_vs_q(\n",
    "    #     num_threads, oop=oop, num_bins=1000)\n",
    "    \n",
    "    # Uncomment to get intensity vs 2theta.\n",
    "    # intensity, tth = experiment.intensity_vs_tth(\n",
    "    #     num_threads, oop=oop, num_bins=1000)\n",
    "\n",
    "    # Finally, print that it's finished We'll use this to work out when the\n",
    "    # processing is done.\n",
    "    print(\"PROCESSING FINISHED.\")\n",
    "\n",
    "class DontContinue(Exception):\n",
    "    \"\"\"Raise to stop processing at this cell\"\"\"\n",
    "\n",
    "\n",
    "raise DontContinue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**ESSENTIAL**\n",
    "\n",
    "This is the cell that you should execute to run this notebook on the cluster.\n",
    "\n",
    "DO NOT EXECUTE THIS MULTIPLE TIMES. IT WILL SUBMIT MULTIPLE JOBS TO THE CLUSTER.\n",
    "PLEASE BE RESPONSIBLE.\n",
    "\"\"\"\n",
    "\n",
    "# We need this to grab the current working directory.\n",
    "import os\n",
    "\n",
    "# We'll need this to run the program that will submit the cluster job.\n",
    "# This module isn't needed for the calculation itself, which is why it is\n",
    "# imported here.\n",
    "import subprocess\n",
    "\n",
    "# First, we save this as \"map.py\". Make sure it doesn't already exist.\n",
    "try:\n",
    "    os.remove(\"map.py\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# Convert this notebook to a python script in our home directory.\n",
    "!jupyter nbconvert --to script map.ipynb\n",
    "\n",
    "# Submit the job, which in turn loads the Hamilton module and runs:\n",
    "# qsub -pe smp 40 -l m_mem_free=2.5G -P i07 cluster_job.sh\n",
    "subprocess.run([\"sh\", \"/dls_sw/apps/fast_rsm/current/scripts/cluster_sub.sh\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following cells contain convenience tools for e.g. interacting with and\n",
    "visualising data.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**IGNORE**\n",
    "\n",
    "This cell just defines a couple of handy functions. Feel free to ignore.\n",
    "\"\"\"\n",
    "\n",
    "def most_recent_cluster_output():\n",
    "    \"\"\"\n",
    "    Returns the filename of the most recent cluster stdout output.\n",
    "    \"\"\"\n",
    "    # Get all the cluster job files that have been created.\n",
    "    files = [x for x in os.listdir() if x.startswith(\"cluster_job.sh.o\")]\n",
    "    numbers = [int(x[16:]) for x in files]\n",
    "\n",
    "    # Work out which cluster job is the most recent.\n",
    "    most_recent_job_no = np.max(numbers)\n",
    "    most_recent_file = \"\"\n",
    "    for file in files:\n",
    "        if str(most_recent_job_no) in file:\n",
    "            most_recent_file = file\n",
    "\n",
    "    return most_recent_file\n",
    "\n",
    "\n",
    "def most_recent_cluster_error():\n",
    "    \"\"\"\n",
    "    Returns the filename of the most recent cluster stderr output.\n",
    "    \"\"\"\n",
    "    # Get all the cluster job files that have been created.\n",
    "    files = [x for x in os.listdir() if x.startswith(\"cluster_job.sh.e\")]\n",
    "    numbers = [int(x[16:]) for x in files]\n",
    "\n",
    "    # Work out which cluster job is the most recent.\n",
    "    most_recent_job_no = np.max(numbers)\n",
    "    most_recent_file = \"\"\n",
    "    for file in files:\n",
    "        if str(most_recent_job_no) in file:\n",
    "            most_recent_file = file\n",
    "\n",
    "    return most_recent_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Are we nearly there yet?\n",
    "\n",
    "Executing this cell tells you if your most recent cluster submission has\n",
    "finished executing.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Get all the cluster job files that have been created.\n",
    "files = [x for x in os.listdir() if x.startswith(\"cluster_job.sh.o\")]\n",
    "numbers = [int(x[16:]) for x in files]\n",
    "\n",
    "# Work out which cluster job is the most recent.\n",
    "most_recent_job_no = np.max(numbers)\n",
    "most_recent_file = \"\"\n",
    "for file in files:\n",
    "    if str(most_recent_job_no) in file:\n",
    "        most_recent_file = file\n",
    "\n",
    "# Open that file, and see if it ends in \"Finished.\"\n",
    "with open(most_recent_file, 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "    # Check if there's nothing in the file yet.\n",
    "    if len(lines) == 0:\n",
    "        print(\"Processing either not started or crashed.\")\n",
    "    last_line = lines[-1].strip()\n",
    "    if last_line.startswith(\"PROCESSING FINISHED.\"):\n",
    "        print(\"Most recent processing has completed.\")\n",
    "    else:\n",
    "        print(\"Most recent processing has not yet completed.\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('fast_rsm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d3d0365b0cf09d8aafe0187e5e70cb1582c70373590192715db7909432628a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
